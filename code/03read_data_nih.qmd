---
title: "Read, clean and join NIH data"
format: html
editor: source
---

# Summary of what this script does

## Data Downloaded

  - NIH ExPORTER: FY 2014-2024, 828,249 US grants (1.9 GB)
  - FY 2025-2026 not yet available on ExPORTER bulk download
  - Files saved to data_raw/nih_exporter/

  ## Join Test Results

  - 97% match rate: 5,649 of 5,812 cut grants found in ExPORTER
  - 163 unmatched: Likely FY 2025 grants not yet in ExPORTER
  - Join key: core_project_num (ExPORTER) â†” core_award_number (Grant Witness)

  ## Column Recommendations

  ### From ExPORTER (23 columns) - authoritative source:
  - IDs: application_id, core_project_num, full_project_num
  - Agency: administering_ic, ic_name
  - PI: pi_ids, pi_names
  - Org: org_name, org_city, org_state
  - Project: project_title, project_terms, phr (Public Health Relevance), nih_spending_cats, abstract_text
  - Dates: fiscal_year, project_start, project_end
  - Budget: total_cost, direct_cost_amt, indirect_cost_amt
  - Metadata: activity, funding_mechanism, study_section

  ### From Grant Witness (19 columns) - termination-specific only:
  - Status: status, ever_frozen
  - Dates: frozen_date, unfrozen_date, termination_date, targeted_start/end_date
  - Reinstatement: reinstatement_indicator, reinstated_est_date
  - Spending: total_estimated_outlays, total_estimated_remaining, last_payment_date
  - Analysis: flagged_words, cancellation_source
  - Political: org_congdist, us_rep
  - URLs: usaspending_url, reporter_url

# CODE

```{r}
# Packages
library(tidyverse)
library(lubridate)  # for date parsing (mdy)
library(here)

# Settings for this script
fiscal_years <- 2014:2024 # (2025 and 2026 don't exist as bulk download)
data_dir <- here("data_raw/nih_exporter")

# Create directory if it doesn't exist
if (!dir.exists(data_dir)) {
  dir.create(data_dir, recursive = TRUE)
}
```

## Download NIH ExPORTER data

ExPORTER provides bulk downloads of NIH grant data by fiscal year.
Source: https://reporter.nih.gov/exporter/
Abstract files (download-abstracts chunk) - from https://reporter.nih.gov/exporter/abstracts/download/<fy> for 2014-2024

```{r download-exporter}
# Download ExPORTER project files for fiscal years 2014-2026
# Files are ZIP archives containing CSV data
# URL format: https://reporter.nih.gov/exporter/projects/download/<fy>

# Download each fiscal year (skip if already downloaded)
for (fy in fiscal_years) {
  zip_file <- file.path(data_dir, paste0("RePORTER_PRJ_C_FY", fy, ".zip"))

  if (!file.exists(zip_file)) {
    url <- paste0("https://reporter.nih.gov/exporter/projects/download/", fy)
    cat("Downloading FY", fy, "...\n")

    # Try download, handle potential errors
    tryCatch({
      download.file(url, zip_file, mode = "wb", quiet = FALSE)
      cat("  Downloaded successfully\n")
    }, error = function(e) {
      cat("  Error downloading FY", fy, ":", e$message, "\n")
    })

    # Be polite to the server
    Sys.sleep(2)
  } else {
    cat("FY", fy, "already exists, skipping\n")
  }
}

# List downloaded files
list.files(data_dir, pattern = "\\.zip$")
```

```{r download-abstracts}
# Download ExPORTER abstract files for fiscal years 2014-2024
# URL format: https://reporter.nih.gov/exporter/abstracts/download/<fy>

for (fy in fiscal_years) {
  zip_file <- file.path(data_dir, paste0("RePORTER_PRJABS_C_FY", fy, ".zip"))

  if (!file.exists(zip_file)) {
    url <- paste0("https://reporter.nih.gov/exporter/abstracts/download/", fy)
    cat("Downloading abstracts FY", fy, "...\n")

    tryCatch({
      download.file(url, zip_file, mode = "wb", quiet = FALSE)
      cat("  Downloaded successfully\n")
    }, error = function(e) {
      cat("  Error downloading abstracts FY", fy, ":", e$message, "\n")
    })

    Sys.sleep(2)
  } else {
    cat("Abstracts FY", fy, "already exists, skipping\n")
  }
}

# List abstract files
list.files(data_dir, pattern = "PRJABS.*\\.zip$")
```


## Extract, read and join bulk download EXPORTER datasets

```{r extract-and-read}
# Extract and read all CSV files from the ZIP archives
# Filter for US grants only (Organization Country == "UNITED STATES")
# Skip if cached RDS file already exists

# Define cache file paths
exporter_cache <- here("data/nih_exporter_usa_2014_2024.rds")
combined_cache <- here("data/nih_exporter_usa_2014_2025.rds")

# Check for most complete cache first (combined 2014-2025)
# If it exists, skip ALL processing and load it directly later
skip_all_processing <- file.exists(combined_cache)

if (skip_all_processing) {
  cat("Combined 2014-2025 cache found at:", combined_cache, "\n")
  cat("Skipping all data processing. Delete cache file to reprocess.\n")
  skip_exporter_processing <- TRUE
} else if (file.exists(exporter_cache)) {
  cat("Cached ExPORTER 2014-2024 data found at:", exporter_cache, "\n")
  cat("Skipping ZIP extraction. Delete cache file to reprocess.\n")
  skip_exporter_processing <- TRUE
} else {
  cat("No cache found, extracting and reading ExPORTER ZIP files...\n")
  skip_exporter_processing <- FALSE
}

read_exporter_year <- function(fy, data_dir) {
  zip_file <- file.path(data_dir, paste0("RePORTER_PRJ_C_FY", fy, ".zip"))

  if (!file.exists(zip_file)) {
    cat("ZIP file for FY", fy, "not found\n")
    return(NULL)
  }

  # List contents of ZIP file
  zip_contents <- unzip(zip_file, list = TRUE)
  csv_file <- zip_contents$Name[grepl("\\.csv$", zip_contents$Name)]

  if (length(csv_file) == 0) {
    cat("No CSV found in FY", fy, "ZIP\n")
    return(NULL)
  }

  # Extract to temp location and read
  temp_dir <- tempdir()
  unzip(zip_file, files = csv_file, exdir = temp_dir, overwrite = TRUE)

  # Read CSV
  df <- read_csv(file.path(temp_dir, csv_file), show_col_types = FALSE)

  # Ensure consistent column types across years (some columns are empty in certain years)
  if ("SUBPROJECT_ID" %in% names(df)) {
    df$SUBPROJECT_ID <- as.character(df$SUBPROJECT_ID)
  }

  # Add fiscal year column if not present
  if (!"FISCAL_YEAR" %in% names(df)) {
    df$FISCAL_YEAR <- fy
  }

  cat("FY", fy, ":", nrow(df), "rows,", ncol(df), "columns\n")
  return(df)
}

# Read all fiscal years (only if not using cache)
if (!skip_exporter_processing) {
  nih_exporter_list <- lapply(fiscal_years, read_exporter_year, data_dir = data_dir)
  # Remove NULL entries (failed downloads)
  nih_exporter_list <- nih_exporter_list[!sapply(nih_exporter_list, is.null)]
}
```

```{r combine-datasets}
# Combine all years into one dataset (skip if using cache)
if (!skip_exporter_processing) {
  nih_exporter_all <- bind_rows(nih_exporter_list)

  cat("\nCombined dataset:\n")
  cat("  Total rows:", nrow(nih_exporter_all), "\n")
  cat("  Total columns:", ncol(nih_exporter_all), "\n")

  # Filter for United States only
  nih_exporter_usa <- nih_exporter_all %>%
    filter(ORG_COUNTRY == "UNITED STATES")

  cat("\nUS grants only:\n")
  cat("  Total rows:", nrow(nih_exporter_usa), "\n")

  # Summary by fiscal year
  cat("\nGrants per fiscal year:\n")
  print(table(nih_exporter_usa$FISCAL_YEAR))

  # Clean up memory
  rm(nih_exporter_list, nih_exporter_all)
  gc()
}
```

```{r extract-and-read-abstracts}
# Unzip and Read abstract files and join with main data
# Abstract files contain APPLICATION_ID and ABSTRACT_TEXT
# Skip if using cached data (abstracts already joined in cache)

if (skip_exporter_processing) {
  cat("Skipping abstract extraction (using cached data with abstracts)\n")
} else {

read_abstracts_year <- function(fy, data_dir) {
  zip_file <- file.path(data_dir, paste0("RePORTER_PRJABS_C_FY", fy, ".zip"))

  if (!file.exists(zip_file)) {
    cat("Abstract ZIP file for FY", fy, "not found\n")
    return(NULL)
  }

  # List contents of ZIP file
  zip_contents <- unzip(zip_file, list = TRUE)
  csv_file <- zip_contents$Name[grepl("\\.csv$", zip_contents$Name)]

  if (length(csv_file) == 0) {
    cat("No CSV found in abstracts FY", fy, "ZIP\n")
    return(NULL)
  }

  # Extract to temp location and read
  temp_dir <- tempdir()
  unzip(zip_file, files = csv_file, exdir = temp_dir, overwrite = TRUE)

  # Read CSV
  df <- read_csv(file.path(temp_dir, csv_file), show_col_types = FALSE)

  cat("Abstracts FY", fy, ":", nrow(df), "rows\n")
  return(df)
}

# Read all abstract files
  abstracts_list <- lapply(fiscal_years, read_abstracts_year, data_dir = data_dir)
  abstracts_list <- abstracts_list[!sapply(abstracts_list, is.null)]

  # Combine all abstracts
  abstracts_all <- bind_rows(abstracts_list)
  cat("\nTotal abstracts:", nrow(abstracts_all), "\n")

  # Clean up
  rm(abstracts_list)
} # end skip_exporter_processing check
```

```{r join-abstracts}
# Join abstracts to main ExPORTER data by APPLICATION_ID
# Or load from cache if available

if (skip_all_processing) {
  # Skip - will load combined cache later
  cat("Skipping 2014-2024 cache load (will load combined cache later)\n")
} else if (skip_exporter_processing) {
  # Load cached data with abstracts already joined
  nih_exporter_usa <- readRDS(exporter_cache)
  cat("Loaded cached ExPORTER data:\n")
  cat("  Total rows:", nrow(nih_exporter_usa), "\n")
  cat("  Grants with abstracts:", sum(!is.na(nih_exporter_usa$ABSTRACT_TEXT)), "\n")
} else {
  # Join abstracts to main ExPORTER data
  nih_exporter_usa <- nih_exporter_usa %>%
    left_join(
      abstracts_all %>% select(APPLICATION_ID, ABSTRACT_TEXT),
      by = "APPLICATION_ID"
    )

  cat("After joining abstracts:\n")
  cat("  Total rows:", nrow(nih_exporter_usa), "\n")
  cat("  Grants with abstracts:", sum(!is.na(nih_exporter_usa$ABSTRACT_TEXT)), "\n")
  cat("  Grants without abstracts:", sum(is.na(nih_exporter_usa$ABSTRACT_TEXT)), "\n")

  # Clean up
  rm(abstracts_all)
  gc()

  # Save checkpoint: ExPORTER 2014-2024 data with abstracts
  saveRDS(nih_exporter_usa, exporter_cache)
  cat("Saved cache to:", exporter_cache, "\n")
}
```

## Read manually downloaded 2025 NIH Reporter data

NIH Reporter manual downloads (FY 2025) were split by agency groups to avoid the 15,000 record download limit. Files include agencies in the filename.

```{r read-manual-2025}
# Skip 2025 processing if combined cache exists (already checked at start)
skip_2025_processing <- skip_all_processing

if (skip_2025_processing) {
  cat("Skipping 2025 manual data processing (will load combined cache)\n")
} else {

# Find all 2025 manual download CSV files
manual_2025_files <- list.files(
  data_dir,
  pattern = "nih_exporter_year2025.*\\.csv$",
  full.names = TRUE
)

cat("Found", length(manual_2025_files), "manual 2025 files:\n")
print(basename(manual_2025_files))

# Function to read a manual 2025 download file
# These files have 7 header rows before the column names
read_manual_2025 <- function(file_path) {
  # Read skipping the first 7 rows (header metadata)
  df <- read_csv(file_path, skip = 7, show_col_types = FALSE)

  # Comprehensive rename: map NIH Reporter column names to ExPORTER bulk format
  df <- df %>%
    rename(
      # IDs
      APPLICATION_ID = `Application ID`,
      FULL_PROJECT_NUM = `Project Number`,
      SERIAL_NUMBER = `Serial Number`,
      SUBPROJECT_ID = `Subproject Number`,
      SUFFIX = `Suffix`,
      SUPPORT_YEAR = `Support Year`,
      APPLICATION_TYPE = `Type`,
      # Agency/Admin
      ADMINISTERING_IC = `Administering IC`,
      IC = `IC`,
      FUNDING_ICs = `Funding IC(s)`,
      FUNDING_MECHANISM = `Funding Mechanism`,
      FOA_NUMBER = `Opportunity Number`,
      PROGRAM_OFFICER_NAME = `Program Official Information`,
      STUDY_SECTION = `Study Section`,
      # Activity
      ACTIVITY = `Activity`,
      # PI info
      PI_IDS = `Contact PI Person ID`,
      PI_NAMEs = `Contact PI / Project Leader`,
      # Organization
      ORG_NAME = `Organization Name`,
      ORG_CITY = `Organization City`,
      ORG_STATE = `Organization State`,
      ORG_COUNTRY = `Organization Country`,
      ORG_ZIPCODE = `Organization Zip`,
      ORG_DISTRICT = `Congressional District`,
      ORG_DEPT = `Department`,
      ORG_DUNS = `DUNS Number`,
      ORG_FIPS = `FIPS`,
      ORG_IPF_CODE = `Organization ID (IPF)`,
      ED_INST_TYPE = `Organization Type`,
      # Project content
      PROJECT_TITLE = `Project Title`,
      PROJECT_TERMS = `Project Terms`,
      PHR = `Public Health Relevance`,
      NIH_SPENDING_CATS = `NIH Spending Categorization`,
      ABSTRACT_TEXT = `Project Abstract`,
      # Dates
      FISCAL_YEAR = `Fiscal Year`,
      PROJECT_START = `Project Start Date`,
      PROJECT_END = `Project End Date`,
      AWARD_NOTICE_DATE = `Award Notice Date`,
      BUDGET_START = `Budget Start Date`,
      BUDGET_END = `Budget End Date`,
      # Budget
      TOTAL_COST = `Total Cost`,
      TOTAL_COST_SUB_PROJECT = `Total Cost(Sub Projects)`,
      DIRECT_COST_AMT = `Direct Cost IC`,
      INDIRECT_COST_AMT = `Indirect Cost IC`,
      # Other
      ARRA_FUNDED = `ARRA Indicator`,
      CFDA_CODE = `Assistance Listing Number`
    )

  # Convert date columns from character (m/d/Y format) to Date
  df <- df %>%
    mutate(
      PROJECT_START = mdy(PROJECT_START),
      PROJECT_END = mdy(PROJECT_END),
      BUDGET_START = mdy(BUDGET_START),
      BUDGET_END = mdy(BUDGET_END),
      AWARD_NOTICE_DATE = mdy(AWARD_NOTICE_DATE)
    )

  # Ensure SUBPROJECT_ID is character for consistency with ExPORTER
  df <- df %>%
    mutate(SUBPROJECT_ID = as.character(SUBPROJECT_ID))

  # Extract CORE_PROJECT_NUM from FULL_PROJECT_NUM
  # FULL_PROJECT_NUM format: "3R01FD007630-01S4" -> CORE_PROJECT_NUM: "R01FD007630"
  df <- df %>%
    mutate(
      CORE_PROJECT_NUM = str_extract(FULL_PROJECT_NUM, "[A-Z][0-9]{2}[A-Z]{2}[0-9]+")
    )

  cat("  Read", basename(file_path), ":", nrow(df), "rows\n")
  return(df)
}

# Read all manual 2025 files
nih_2025_list <- lapply(manual_2025_files, read_manual_2025)

# Combine all 2025 data
nih_2025_all <- bind_rows(nih_2025_list)

cat("\nManual 2025 data combined:\n")
cat("  Total rows:", nrow(nih_2025_all), "\n")
cat("  Total columns:", ncol(nih_2025_all), "\n")
cat("  Unique grants:", n_distinct(nih_2025_all$CORE_PROJECT_NUM), "\n")

# Clean up
rm(nih_2025_list)
} # end skip_2025_processing check
```

## Combine NIH Exporter data from 2014-2024 with 2025 data

```{r combine-manual-with-exporter}
# Combine 2025 manual data with ExPORTER bulk data (2014-2024)
# Or load from cache if available

if (skip_2025_processing) {
  # Load combined cache
  nih_exporter_usa <- readRDS(combined_cache)
  cat("Loaded combined 2014-2025 cache:\n")
  cat("  Total rows:", nrow(nih_exporter_usa), "\n")
  cat("\nGrants per fiscal year:\n")
  print(table(nih_exporter_usa$fiscal_year))
} else {
  # Combine 2025 manual data with ExPORTER bulk data
  cat("ExPORTER columns:", ncol(nih_exporter_usa), "\n")
  cat("Manual 2025 columns:", ncol(nih_2025_all), "\n")

  common_cols_2025 <- intersect(names(nih_exporter_usa), names(nih_2025_all))
  cat("Common columns between ExPORTER and 2025 manual:", length(common_cols_2025), "\n")
  cat("Common columns:\n")
  print(common_cols_2025)

  # Ensure consistent column types before binding
  # Some columns are character in one dataset and numeric in another
  cols_to_character <- c("PI_IDS", "CFDA_CODE", "SUBPROJECT_ID", "SUFFIX",
                         "SUPPORT_YEAR", "APPLICATION_TYPE", "ORG_DUNS",
                         "ORG_FIPS", "ORG_ZIPCODE", "ORG_DISTRICT", "SERIAL_NUMBER")

  for (col in cols_to_character) {
    if (col %in% names(nih_exporter_usa)) {
      nih_exporter_usa[[col]] <- as.character(nih_exporter_usa[[col]])
    }
    if (col %in% names(nih_2025_all)) {
      nih_2025_all[[col]] <- as.character(nih_2025_all[[col]])
    }
  }

  # Add 2025 data to ExPORTER USA data
  nih_exporter_usa <- bind_rows(
    nih_exporter_usa,
    nih_2025_all %>% select(all_of(common_cols_2025))
  )

  # Convert all column names to lowercase for easier typing
  names(nih_exporter_usa) <- tolower(names(nih_exporter_usa))

  cat("\nCombined ExPORTER + 2025 manual data:\n")
  cat("  Total rows:", nrow(nih_exporter_usa), "\n")
  cat("\nGrants per fiscal year (including 2025):\n")
  print(table(nih_exporter_usa$fiscal_year))

  # Clean up
  rm(nih_2025_all)
  gc()

  # Save combined cache
  saveRDS(nih_exporter_usa, combined_cache)
  cat("Saved combined cache to:", combined_cache, "\n")
}
```

## Read Grant Witness NIH terminations

```{r read-grant-witness}
# SOURCE: Grant Witness - https://www.grant-witness.us
nih_cut <- read_csv(here('data/grant_witness_nih_terminations.csv'), show_col_types = FALSE)

cat("Grant Witness NIH terminations:\n")
cat("  Rows:", nrow(nih_cut), "\n")
cat("  Columns:", ncol(nih_cut), "\n")
```

## Column Analysis and Recommendations

### ExPORTER Columns (48 columns) - Authoritative source for all grants

**Identifiers:**
- application_id, core_project_num (join key), full_project_num
- serial_number, subproject_id, suffix, support_year

**Grant metadata:**
- activity, application_type, funding_mechanism, cfda_code, foa_number

**Agency/Admin:**
- administering_ic, ic_name, funding_ics, program_officer_name
- study_section, study_section_name

**Organization:**
- org_name, org_city, org_state, org_country, org_dept, org_zipcode
- org_district, org_duns, org_fips, org_ipf_code, ed_inst_type

**PI:** pi_ids, pi_names

**Project:** project_title, project_terms, phr, nih_spending_cats

**Dates:** fiscal_year, project_start, project_end, budget_start, budget_end, award_notice_date

**Budget:** total_cost, direct_cost_amt, indirect_cost_amt, total_cost_sub_project

### Grant Witness Columns (56 columns) - Termination-specific data

**Overlapping with ExPORTER (use ExPORTER version):**
- project_title, activity_code, org_name, org_state, org_city, terms
- phr_text, study_section, foa, total_award

**Unique termination-specific columns to KEEP:**
- status, ever_frozen, frozen_date, unfrozen_date
- termination_date, targeted_start_date, targeted_end_date
- reinstatement_indicator, reinstated_est_date, reinstatement_case
- last_payment_date, cancellation_source
- total_estimated_outlays, total_estimated_remaining
- file_c_outlays (detailed outlay history)
- flagged_words (analysis of concerning terms)
- us_rep, us_rep_phone, org_congdist (political data)
- court_reported, court_restoration_url (legal info)
- usaspending_url, taggs_url, reporter_url (reference links)

```{r column-recommendation}
# Recommended columns from each dataset

# From ExPORTER (authoritative grant data)
# Using column names that exist in both bulk download AND manual 2025 data
exporter_cols <- c(
  # IDs
  "application_id", "core_project_num", "full_project_num",
  # Agency
  "administering_ic", "study_section", "funding_mechanism",
  # PI
  "pi_ids", "pi_names",
  # Organization
  "org_name", "org_city", "org_state", "org_zipcode", "org_country",
  "org_district", "org_dept", "ed_inst_type",
  # Project
  "project_title", "project_terms", "phr", "nih_spending_cats",
  "abstract_text",
  # Dates
  "fiscal_year", "project_start", "project_end",
  # Budget
  "total_cost", "direct_cost_amt", "indirect_cost_amt"
)

# From Grant Witness (termination-specific only)
grantwitness_cols <- c(
  # Join key
  "core_award_number",
  # Status
  "status", "ever_frozen",
  # Termination dates
  "frozen_date", "unfrozen_date", "termination_date",
  "targeted_start_date", "targeted_end_date",
  # Reinstatement
  "reinstatement_indicator", "reinstated_est_date",
  # Spending
  "total_estimated_outlays", "total_estimated_remaining",
  "last_payment_date", "cancellation_source",
  # Analysis
  "flagged_words",
  # Political
  "org_congdist", "us_rep",
  # URLs
  "usaspending_url", "reporter_url"
)

cat("Selected ExPORTER columns:", length(exporter_cols), "\n")
cat("Selected Grant Witness columns:", length(grantwitness_cols), "\n")
```

## Test Join Strategy

Join on CORE_PROJECT_NUM (ExPORTER) = core_award_number (Grant Witness)

```{r test-join}
# Join statistics
matched <- nih_cut %>%
  semi_join(nih_exporter_usa, by = c("core_award_number" = "core_project_num"))

unmatched <- nih_cut %>%
  anti_join(nih_exporter_usa, by = c("core_award_number" = "core_project_num"))

cat("Join results:\n")
cat("  Total cut grants:", nrow(nih_cut), "\n")
cat("  Matched in ExPORTER:", nrow(matched), "(", round(100*nrow(matched)/nrow(nih_cut), 1), "%)\n")
cat("  Unmatched (likely FY 2025):", nrow(unmatched), "\n")
```

## Create Joined Analysis Dataset

Strategy: ExPORTER is authoritative. Keep most recent FY record per grant.
Add termination info from Grant Witness where available.

```{r create-joined-dataset}
# Get most recent ExPORTER record per grant
nih_exporter_latest <- nih_exporter_usa %>%
  group_by(core_project_num) %>%
  filter(fiscal_year == max(fiscal_year)) %>%
  slice(1) %>%  # In case of ties, take first
  ungroup()

cat("ExPORTER deduplicated:", nrow(nih_exporter_latest), "unique grants\n")

# Select columns from Grant Witness (termination-specific only)
nih_cut_slim <- nih_cut %>%
  select(all_of(grantwitness_cols))

# Join: all grants from ExPORTER, add termination info where available
nih_joined <- nih_exporter_latest %>%
  select(all_of(exporter_cols)) %>%
  left_join(nih_cut_slim, by = c("core_project_num" = "core_award_number")) %>%
  mutate(was_cut = !is.na(status))

cat("\nJoined dataset:\n")
cat("  Total rows:", nrow(nih_joined), "\n")
cat("  Total columns:", ncol(nih_joined), "\n")
cat("  Cut grants:", sum(nih_joined$was_cut), "\n")
cat("  Non-cut grants:", sum(!nih_joined$was_cut), "\n")

glimpse(nih_joined)
```

```{r check-lost-grants}
# Which cut grants were lost in the join (not in ExPORTER)?
lost_cuts <- nih_cut %>%
  anti_join(nih_exporter_usa, by = c("core_award_number" = "core_project_num"))

cat("Cut grants not found in ExPORTER:", nrow(lost_cuts), "\n")
cat("These are likely FY 2025 grants not yet in ExPORTER bulk download.\n")

# Show sample
if (nrow(lost_cuts) > 0) {
  cat("\nSample lost grants:\n")
  print(head(lost_cuts %>% select(core_award_number, project_title, status), 10))
}
```

```{r save-analysis-dataset}
# Save joined dataset
write_csv(nih_joined, here('data_analysis/nih_analysis.csv'))
cat("NIH analysis dataset:", nrow(nih_joined), "grants,", ncol(nih_joined), "columns\n")
cat("Saved to data_analysis/nih_analysis.csv\n")
```


# Notes on the analysis file

NIH Analysis Dataset Created

  File: data_analysis/nih_analysis.csv (493 MB)

  Dataset Statistics

  | Metric         | Count   |
  |----------------|---------|
  | Total rows     | 218,480 |
  | Total columns  | 42      |
  | Cut grants     | 5,675   |
  | Non-cut grants | 212,805 |
  | Match rate     | 97.2%   |

  Lost Grants (163)

  The 163 unmatched cut grants appear to be:
  - FY 2025 grants not yet in ExPORTER bulk download
  - Some have no project title (e.g., AY2AX prefixed awards)
  - Mostly newer fellowship awards (F30, F31, K-series)

  Column Structure (42 columns)

  - 23 from ExPORTER: Grant metadata, PI info, org info, dates, budget
  - 18 from Grant Witness: Termination status, dates, spending, political info, URLs
  - 1 derived: was_cut (TRUE/FALSE flag)

  The dataset follows the same structure as your NSF analysis - ExPORTER as authoritative source for all grants, with termination-specific info from Grant Witness added where applicable.