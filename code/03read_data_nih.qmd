---
title: "Read, clean and join NIH data"
format: html
editor: source
---

# Summary of what this script does

## Data Downloaded

  - NIH ExPORTER: FY 2014-2024, 828,249 US grants (1.9 GB)
  - FY 2025-2026 not yet available on ExPORTER bulk download
  - Files saved to data_raw/nih_exporter/

  # Join Test Results

  - 97% match rate: 5,649 of 5,812 cut grants found in ExPORTER
  - 163 unmatched: Likely FY 2025 grants not yet in ExPORTER
  - Join key: CORE_PROJECT_NUM (ExPORTER) â†” core_award_number (Grant Witness)

  ## Column Recommendations

  ### From ExPORTER (23 columns) - authoritative source:
  - IDs: APPLICATION_ID, CORE_PROJECT_NUM, FULL_PROJECT_NUM
  - Agency: ADMINISTERING_IC, IC_NAME
  - PI: PI_IDS, PI_NAMEs
  - Org: ORG_NAME, ORG_CITY, ORG_STATE
  - Project: PROJECT_TITLE, PROJECT_TERMS, PHR, NIH_SPENDING_CATS
  - Dates: FY, PROJECT_START, PROJECT_END
  - Budget: TOTAL_COST, DIRECT_COST_AMT, INDIRECT_COST_AMT
  - Metadata: ACTIVITY, FUNDING_MECHANISM, STUDY_SECTION

  ### From Grant Witness (19 columns) - termination-specific only:
  - Status: status, ever_frozen
  - Dates: frozen_date, unfrozen_date, termination_date, targeted_start/end_date
  - Reinstatement: reinstatement_indicator, reinstated_est_date
  - Spending: total_estimated_outlays, total_estimated_remaining, last_payment_date
  - Analysis: flagged_words, cancellation_source
  - Political: org_congdist, us_rep
  - URLs: usaspending_url, reporter_url


```{r}
# Packages
library(tidyverse)
library(lubridate)  # for date parsing (mdy)
library(here)
```

## Download NIH ExPORTER data

ExPORTER provides bulk downloads of NIH grant data by fiscal year.
Source: https://reporter.nih.gov/exporter/

```{r download-exporter}
# Download ExPORTER project files for fiscal years 2014-2026
# Files are ZIP archives containing CSV data
# URL format: https://reporter.nih.gov/exporter/projects/download/<fy>

fiscal_years <- 2014:2024 # (2025 and 2026 don't exist as bulk download)
data_dir <- here("data_raw/nih_exporter")

# Create directory if it doesn't exist
if (!dir.exists(data_dir)) {
  dir.create(data_dir, recursive = TRUE)
}

# Download each fiscal year (skip if already downloaded)
for (fy in fiscal_years) {
  zip_file <- file.path(data_dir, paste0("RePORTER_PRJ_C_FY", fy, ".zip"))

  if (!file.exists(zip_file)) {
    url <- paste0("https://reporter.nih.gov/exporter/projects/download/", fy)
    cat("Downloading FY", fy, "...\n")

    # Try download, handle potential errors
    tryCatch({
      download.file(url, zip_file, mode = "wb", quiet = FALSE)
      cat("  Downloaded successfully\n")
    }, error = function(e) {
      cat("  Error downloading FY", fy, ":", e$message, "\n")
    })

    # Be polite to the server
    Sys.sleep(2)
  } else {
    cat("FY", fy, "already exists, skipping\n")
  }
}

# List downloaded files
list.files(data_dir, pattern = "\\.zip$")
```

```{r download-abstracts}
# Download ExPORTER abstract files for fiscal years 2014-2024
# URL format: https://reporter.nih.gov/exporter/abstracts/download/<fy>

for (fy in fiscal_years) {
  zip_file <- file.path(data_dir, paste0("RePORTER_PRJABS_C_FY", fy, ".zip"))

  if (!file.exists(zip_file)) {
    url <- paste0("https://reporter.nih.gov/exporter/abstracts/download/", fy)
    cat("Downloading abstracts FY", fy, "...\n")

    tryCatch({
      download.file(url, zip_file, mode = "wb", quiet = FALSE)
      cat("  Downloaded successfully\n")
    }, error = function(e) {
      cat("  Error downloading abstracts FY", fy, ":", e$message, "\n")
    })

    Sys.sleep(2)
  } else {
    cat("Abstracts FY", fy, "already exists, skipping\n")
  }
}

# List abstract files
list.files(data_dir, pattern = "PRJABS.*\\.zip$")
```

```{r extract-and-read}
# Extract and read all CSV files from the ZIP archives
# Filter for US grants only (Organization Country == "UNITED STATES")

read_exporter_year <- function(fy, data_dir) {
  zip_file <- file.path(data_dir, paste0("RePORTER_PRJ_C_FY", fy, ".zip"))

  if (!file.exists(zip_file)) {
    cat("ZIP file for FY", fy, "not found\n")
    return(NULL)
  }

  # List contents of ZIP file
  zip_contents <- unzip(zip_file, list = TRUE)
  csv_file <- zip_contents$Name[grepl("\\.csv$", zip_contents$Name)]

  if (length(csv_file) == 0) {
    cat("No CSV found in FY", fy, "ZIP\n")
    return(NULL)
  }

  # Extract to temp location and read
  temp_dir <- tempdir()
  unzip(zip_file, files = csv_file, exdir = temp_dir, overwrite = TRUE)

  # Read CSV
  df <- read_csv(file.path(temp_dir, csv_file), show_col_types = FALSE)

  # Ensure consistent column types across years (some columns are empty in certain years)
  if ("SUBPROJECT_ID" %in% names(df)) {
    df$SUBPROJECT_ID <- as.character(df$SUBPROJECT_ID)
  }

  # Add fiscal year column if not present
  if (!"FISCAL_YEAR" %in% names(df)) {
    df$FISCAL_YEAR <- fy
  }

  cat("FY", fy, ":", nrow(df), "rows,", ncol(df), "columns\n")
  return(df)
}

# Read all fiscal years
nih_exporter_list <- lapply(fiscal_years, read_exporter_year, data_dir = data_dir)

# Remove NULL entries (failed downloads)
nih_exporter_list <- nih_exporter_list[!sapply(nih_exporter_list, is.null)]
```

```{r combine-datasets}
# Combine all years into one dataset
nih_exporter_all <- bind_rows(nih_exporter_list)

cat("\nCombined dataset:\n")
cat("  Total rows:", nrow(nih_exporter_all), "\n")
cat("  Total columns:", ncol(nih_exporter_all), "\n")

# Filter for United States only
nih_exporter_usa <- nih_exporter_all %>%
  filter(ORG_COUNTRY == "UNITED STATES")

cat("\nUS grants only:\n")
cat("  Total rows:", nrow(nih_exporter_usa), "\n")

# Summary by fiscal year
cat("\nGrants per fiscal year:\n")
print(table(nih_exporter_usa$FISCAL_YEAR))

# Clean up memory
rm(nih_exporter_list, nih_exporter_all)
gc()
```

```{r read-abstracts}
# Read abstract files and join with main data
# Abstract files contain APPLICATION_ID and ABSTRACT_TEXT

read_abstracts_year <- function(fy, data_dir) {
  zip_file <- file.path(data_dir, paste0("RePORTER_PRJABS_C_FY", fy, ".zip"))

  if (!file.exists(zip_file)) {
    cat("Abstract ZIP file for FY", fy, "not found\n")
    return(NULL)
  }

  # List contents of ZIP file
  zip_contents <- unzip(zip_file, list = TRUE)
  csv_file <- zip_contents$Name[grepl("\\.csv$", zip_contents$Name)]

  if (length(csv_file) == 0) {
    cat("No CSV found in abstracts FY", fy, "ZIP\n")
    return(NULL)
  }

  # Extract to temp location and read
  temp_dir <- tempdir()
  unzip(zip_file, files = csv_file, exdir = temp_dir, overwrite = TRUE)

  # Read CSV
  df <- read_csv(file.path(temp_dir, csv_file), show_col_types = FALSE)

  cat("Abstracts FY", fy, ":", nrow(df), "rows\n")
  return(df)
}

# Read all abstract files
abstracts_list <- lapply(fiscal_years, read_abstracts_year, data_dir = data_dir)
abstracts_list <- abstracts_list[!sapply(abstracts_list, is.null)]

# Combine all abstracts
abstracts_all <- bind_rows(abstracts_list)
cat("\nTotal abstracts:", nrow(abstracts_all), "\n")

# Clean up
rm(abstracts_list)
```

```{r join-abstracts}
# Join abstracts to main ExPORTER data by APPLICATION_ID
nih_exporter_usa <- nih_exporter_usa %>%
  left_join(
    abstracts_all %>% select(APPLICATION_ID, ABSTRACT_TEXT),
    by = "APPLICATION_ID"
  )

cat("After joining abstracts:\n")
cat("  Total rows:", nrow(nih_exporter_usa), "\n")
cat("  Grants with abstracts:", sum(!is.na(nih_exporter_usa$ABSTRACT_TEXT)), "\n")
cat("  Grants without abstracts:", sum(is.na(nih_exporter_usa$ABSTRACT_TEXT)), "\n")

# Clean up
rm(abstracts_all)
gc()

# Save checkpoint: ExPORTER 2014-2024 data with abstracts
saveRDS(nih_exporter_usa, here("data/nih_exporter_usa_2014_2024.rds"))
# To reload: nih_exporter_usa <- readRDS(here("data/nih_exporter_usa_2014_2024.rds"))
```

## Read manually downloaded 2025 NIH Reporter data

NIH Reporter manual downloads (FY 2025) were split by agency groups to avoid the 15,000 record download limit. Files include agencies in the filename.

```{r read-manual-2025}
# Find all 2025 manual download CSV files
manual_2025_files <- list.files(
  data_dir,
  pattern = "nih_exporter_year2025.*\\.csv$",
  full.names = TRUE
)

cat("Found", length(manual_2025_files), "manual 2025 files:\n")
print(basename(manual_2025_files))

# Function to read a manual 2025 download file
# These files have 7 header rows before the column names
read_manual_2025 <- function(file_path) {
  # Read skipping the first 7 rows (header metadata)
  df <- read_csv(file_path, skip = 7, show_col_types = FALSE)

  # Rename columns to match ExPORTER bulk download format
  df <- df %>%
    rename(
      APPLICATION_ID = `Application ID`,
      FULL_PROJECT_NUM = `Project Number`,
      IC_NAME = `Administering IC`,  # Note: Reporter uses IC code, not full name
      PI_NAMEs = `Contact PI / Project Leader`,
      ORG_NAME = `Organization Name`,
      ORG_CITY = `Organization City`,
      ORG_STATE = `Organization State`,
      ORG_COUNTRY = `Organization Country`,
      ED_INST_TYPE = `Organization Type`,
      PROJECT_TITLE = `Project Title`,
      PROJECT_TERMS = `Project Terms`,
      PHR = `Public Health Relevance`,
      NIH_SPENDING_CATS = `NIH Spending Categorization`,
      FISCAL_YEAR = `Fiscal Year`,
      PROJECT_START = `Project Start Date`,
      PROJECT_END = `Project End Date`,
      TOTAL_COST = `Total Cost`,
      STUDY_SECTION_NAME = `Study Section`,
      ACTIVITY = `Activity`,
      SERIAL_NUMBER = `Serial Number`,
      ABSTRACT_TEXT = `Project Abstract`
    )

  # Convert date columns from character (m/d/Y format) to Date
  df <- df %>%
    mutate(
      PROJECT_START = mdy(PROJECT_START),
      PROJECT_END = mdy(PROJECT_END)
    )

  # Extract CORE_PROJECT_NUM from FULL_PROJECT_NUM
  # FULL_PROJECT_NUM format: "3R01FD007630-01S4" -> CORE_PROJECT_NUM: "R01FD007630"
  df <- df %>%
    mutate(
      CORE_PROJECT_NUM = str_extract(FULL_PROJECT_NUM, "[A-Z][0-9]{2}[A-Z]{2}[0-9]+")
    )

  cat("  Read", basename(file_path), ":", nrow(df), "rows\n")
  return(df)
}

# Read all manual 2025 files
nih_2025_list <- lapply(manual_2025_files, read_manual_2025)

# Combine all 2025 data
nih_2025_all <- bind_rows(nih_2025_list)

cat("\nManual 2025 data combined:\n")
cat("  Total rows:", nrow(nih_2025_all), "\n")
cat("  Total columns:", ncol(nih_2025_all), "\n")
cat("  Unique grants:", n_distinct(nih_2025_all$CORE_PROJECT_NUM), "\n")

# Clean up
rm(nih_2025_list)

# Save checkpoint: 2025 manual download data
saveRDS(nih_2025_all, here("data/nih_2025_manual.rds"))
# To reload: nih_2025_all <- readRDS(here("data/nih_2025_manual.rds"))
```

```{r combine-with-exporter}
# Combine 2025 manual data with ExPORTER bulk data (2014-2024)
# Select common columns for binding

common_cols_2025 <- intersect(names(nih_exporter_usa), names(nih_2025_all))
cat("Common columns between ExPORTER and 2025 manual:", length(common_cols_2025), "\n")

# Add 2025 data to ExPORTER USA data
nih_exporter_usa <- bind_rows(
  nih_exporter_usa,
  nih_2025_all %>% select(all_of(common_cols_2025))
)

cat("\nCombined ExPORTER + 2025 manual data:\n")
cat("  Total rows:", nrow(nih_exporter_usa), "\n")
cat("\nGrants per fiscal year (including 2025):\n")
print(table(nih_exporter_usa$FISCAL_YEAR))

# Clean up
rm(nih_2025_all)
gc()

# Save checkpoint: Combined ExPORTER 2014-2024 + 2025 manual data
saveRDS(nih_exporter_usa, here("data/nih_exporter_usa_2014_2025.rds"))
# To reload: nih_exporter_usa <- readRDS(here("data/nih_exporter_usa_2014_2025.rds"))
```

## Read Grant Witness NIH terminations

```{r read-grant-witness}
# SOURCE: Grant Witness - https://www.grant-witness.us
nih_cut <- read_csv(here('data/grant_witness_nih_terminations.csv'), show_col_types = FALSE)

cat("Grant Witness NIH terminations:\n")
cat("  Rows:", nrow(nih_cut), "\n")
cat("  Columns:", ncol(nih_cut), "\n")
```

## Column Analysis and Recommendations

### ExPORTER Columns (46 columns) - Authoritative source for all grants

**Identifiers:**
- APPLICATION_ID, CORE_PROJECT_NUM (join key), FULL_PROJECT_NUM
- SERIAL_NUMBER, SUBPROJECT_ID, SUFFIX, SUPPORT_YEAR

**Grant metadata:**
- ACTIVITY, APPLICATION_TYPE, FUNDING_MECHANISM, CFDA_CODE, OPPORTUNITY NUMBER

**Agency/Admin:**
- ADMINISTERING_IC, IC_NAME, FUNDING_ICs, PROGRAM_OFFICER_NAME
- STUDY_SECTION, STUDY_SECTION_NAME

**Organization:**
- ORG_NAME, ORG_CITY, ORG_STATE, ORG_COUNTRY, ORG_DEPT, ORG_ZIPCODE
- ORG_DISTRICT, ORG_DUNS, ORG_FIPS, ORG_IPF_CODE, ED_INST_TYPE

**PI:** PI_IDS, PI_NAMEs

**Project:** PROJECT_TITLE, PROJECT_TERMS, PHR, NIH_SPENDING_CATS

**Dates:** FY, PROJECT_START, PROJECT_END, BUDGET_START, BUDGET_END, AWARD_NOTICE_DATE

**Budget:** TOTAL_COST, DIRECT_COST_AMT, INDIRECT_COST_AMT, TOTAL_COST_SUB_PROJECT

### Grant Witness Columns (56 columns) - Termination-specific data

**Overlapping with ExPORTER (use ExPORTER version):**
- project_title, activity_code, org_name, org_state, org_city, terms
- phr_text, study_section, foa, total_award

**Unique termination-specific columns to KEEP:**
- status, ever_frozen, frozen_date, unfrozen_date
- termination_date, targeted_start_date, targeted_end_date
- reinstatement_indicator, reinstated_est_date, reinstatement_case
- last_payment_date, cancellation_source
- total_estimated_outlays, total_estimated_remaining
- file_c_outlays (detailed outlay history)
- flagged_words (analysis of concerning terms)
- us_rep, us_rep_phone, org_congdist (political data)
- court_reported, court_restoration_url (legal info)
- usaspending_url, taggs_url, reporter_url (reference links)

```{r column-recommendation}
# Recommended columns from each dataset

# From ExPORTER (authoritative grant data)
exporter_cols <- c(
  # IDs
  "APPLICATION_ID", "CORE_PROJECT_NUM", "FULL_PROJECT_NUM",
  # Agency
  "IC_NAME", "STUDY_SECTION_NAME",
  # PI
  "PI_NAMEs",
  # Organization
  "ORG_NAME", "ORG_CITY", "ORG_STATE", "ED_INST_TYPE",
  # Project
  "PROJECT_TITLE", "PROJECT_TERMS", "PHR", "NIH_SPENDING_CATS",
  "ABSTRACT_TEXT",
  # Dates
  "FISCAL_YEAR", "PROJECT_START", "PROJECT_END",
  # Budget
  "TOTAL_COST"
)

# From Grant Witness (termination-specific only)
grantwitness_cols <- c(
  # Join key
  "core_award_number",
  # Status
  "status", "ever_frozen",
  # Termination dates
  "frozen_date", "unfrozen_date", "termination_date",
  "targeted_start_date", "targeted_end_date",
  # Reinstatement
  "reinstatement_indicator", "reinstated_est_date",
  # Spending
  "total_estimated_outlays", "total_estimated_remaining",
  "last_payment_date", "cancellation_source",
  # Analysis
  "flagged_words",
  # Political
  "org_congdist", "us_rep",
  # URLs
  "usaspending_url", "reporter_url"
)

cat("Selected ExPORTER columns:", length(exporter_cols), "\n")
cat("Selected Grant Witness columns:", length(grantwitness_cols), "\n")
```

## Test Join Strategy

Join on CORE_PROJECT_NUM (ExPORTER) = core_award_number (Grant Witness)

```{r test-join}
# Join statistics
matched <- nih_cut %>%
  semi_join(nih_exporter_usa, by = c("core_award_number" = "CORE_PROJECT_NUM"))

unmatched <- nih_cut %>%
  anti_join(nih_exporter_usa, by = c("core_award_number" = "CORE_PROJECT_NUM"))

cat("Join results:\n")
cat("  Total cut grants:", nrow(nih_cut), "\n")
cat("  Matched in ExPORTER:", nrow(matched), "(", round(100*nrow(matched)/nrow(nih_cut), 1), "%)\n")
cat("  Unmatched (likely FY 2025):", nrow(unmatched), "\n")
```

## Create Joined Analysis Dataset

Strategy: ExPORTER is authoritative. Keep most recent FY record per grant.
Add termination info from Grant Witness where available.

```{r create-joined-dataset}
# Get most recent ExPORTER record per grant
nih_exporter_latest <- nih_exporter_usa %>%
  group_by(CORE_PROJECT_NUM) %>%
  filter(FY == max(FY)) %>%
  slice(1) %>%  # In case of ties, take first
  ungroup()

cat("ExPORTER deduplicated:", nrow(nih_exporter_latest), "unique grants\n")

# Select columns from Grant Witness (termination-specific only)
nih_cut_slim <- nih_cut %>%
  select(all_of(grantwitness_cols))

# Join: all grants from ExPORTER, add termination info where available
nih_joined <- nih_exporter_latest %>%
  select(all_of(exporter_cols)) %>%
  left_join(nih_cut_slim, by = c("CORE_PROJECT_NUM" = "core_award_number")) %>%
  mutate(was_cut = !is.na(status))

cat("\nJoined dataset:\n")
cat("  Total rows:", nrow(nih_joined), "\n")
cat("  Total columns:", ncol(nih_joined), "\n")
cat("  Cut grants:", sum(nih_joined$was_cut), "\n")
cat("  Non-cut grants:", sum(!nih_joined$was_cut), "\n")

glimpse(nih_joined)
```

```{r check-lost-grants}
# Which cut grants were lost in the join (not in ExPORTER)?
lost_cuts <- nih_cut %>%
  anti_join(nih_exporter_usa, by = c("core_award_number" = "CORE_PROJECT_NUM"))

cat("Cut grants not found in ExPORTER:", nrow(lost_cuts), "\n")
cat("These are likely FY 2025 grants not yet in ExPORTER bulk download.\n")

# Show sample
if (nrow(lost_cuts) > 0) {
  cat("\nSample lost grants:\n")
  print(head(lost_cuts %>% select(core_award_number, project_title, status), 10))
}
```

```{r save-analysis-dataset}
# Save joined dataset
write_csv(nih_joined, here('data_analysis/nih_analysis.csv'))
cat("NIH analysis dataset:", nrow(nih_joined), "grants,", ncol(nih_joined), "columns\n")
cat("Saved to data_analysis/nih_analysis.csv\n")
```


# Notes on the analysis file

NIH Analysis Dataset Created

  File: data_analysis/nih_analysis.csv (493 MB)

  Dataset Statistics

  | Metric         | Count   |
  |----------------|---------|
  | Total rows     | 218,480 |
  | Total columns  | 42      |
  | Cut grants     | 5,675   |
  | Non-cut grants | 212,805 |
  | Match rate     | 97.2%   |

  Lost Grants (163)

  The 163 unmatched cut grants appear to be:
  - FY 2025 grants not yet in ExPORTER bulk download
  - Some have no project title (e.g., AY2AX prefixed awards)
  - Mostly newer fellowship awards (F30, F31, K-series)

  Column Structure (42 columns)

  - 23 from ExPORTER: Grant metadata, PI info, org info, dates, budget
  - 18 from Grant Witness: Termination status, dates, spending, political info, URLs
  - 1 derived: was_cut (TRUE/FALSE flag)

  The dataset follows the same structure as your NSF analysis - ExPORTER as authoritative source for all grants, with termination-specific info from Grant Witness added where applicable.